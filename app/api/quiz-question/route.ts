import { type NextRequest, NextResponse } from "next/server"
import { generateObject } from "ai"
import { openai } from "@ai-sdk/openai"
import { z } from "zod"
import { QUIZ_CATEGORIES } from "@/lib/quiz-categories"

// Sch√©ma pour valider la r√©ponse de l'IA
const QuestionSchema = z.object({
  affirmation: z.string().describe("L'affirmation √† √©valuer"),
  reponse: z.boolean().describe("True si l'affirmation est vraie, false sinon"),
  explication: z.string().describe("Explication d√©taill√©e de la r√©ponse"),
  categorie: z.string().describe("Cat√©gorie de la question"),
  icone: z.string().describe("Ic√¥ne emoji repr√©sentant la cat√©gorie"),
  difficulte: z.enum(["facile", "moyen", "difficile"]).describe("Niveau de difficult√©"),
})

// Questions de fallback par cat√©gorie
const FALLBACK_QUESTIONS = [
  {
    affirmation: "Les for√™ts absorbent plus de CO2 qu'elles n'en rejettent.",
    reponse: true,
    explication:
      "Les for√™ts sont des puits de carbone naturels qui stockent le CO2 de l'atmosph√®re dans leur biomasse.",
    categorie: "For√™ts",
    icone: "üå≥",
    difficulte: "facile" as const,
  },
  {
    affirmation: "L'√©nergie solaire produit plus de CO2 que l'√©nergie nucl√©aire.",
    reponse: false,
    explication:
      "L'√©nergie solaire a une empreinte carbone tr√®s faible, bien inf√©rieure √† celle du nucl√©aire sur l'ensemble du cycle de vie.",
    categorie: "√ânergie",
    icone: "‚ö°",
    difficulte: "moyen" as const,
  },
  {
    affirmation: "Le transport maritime repr√©sente environ 3% des √©missions mondiales de CO2.",
    reponse: true,
    explication:
      "Le transport maritime international repr√©sente environ 2-3% des √©missions mondiales de gaz √† effet de serre.",
    categorie: "Transport",
    icone: "üö¢",
    difficulte: "difficile" as const,
  },
]

export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const { mode, category } = body

    console.log("=== API QUIZ-QUESTION ===")
    console.log("Mode re√ßu:", mode)
    console.log("Cat√©gorie re√ßue:", category)

    // Construire le prompt selon le mode et la cat√©gorie
    let systemPrompt = `Tu es un expert en √©cologie et d√©veloppement durable. G√©n√®re une question sous forme d'affirmation vraie ou fausse sur l'√©cologie, l'environnement, le climat ou le d√©veloppement durable.

L'affirmation doit √™tre :
- Claire et pr√©cise
- √âducative et int√©ressante
- Bas√©e sur des faits scientifiques
- Adapt√©e au niveau demand√©

L'explication doit √™tre :
- P√©dagogique et accessible
- Factuelle et sourc√©e
- Encourageante pour l'apprentissage
- D'environ 1-2 phrases`

    let userPrompt = "G√©n√®re une question √©cologique int√©ressante."

    // Adaptation selon la cat√©gorie pour le mode d√©fi
    if (mode === "challenge" && category) {
      const categoryInfo = QUIZ_CATEGORIES.find((cat) => cat.name === category)
      if (categoryInfo) {
        userPrompt = `G√©n√®re une question sp√©cifiquement sur la cat√©gorie "${category}" (${categoryInfo.description}). La question doit porter sur ${categoryInfo.keywords.join(", ")}.`
        systemPrompt += `\n\nFocus sp√©cial sur la cat√©gorie "${category}": ${categoryInfo.description}`
      }
    }

    // Adaptation selon le mode
    switch (mode) {
      case "expert":
        systemPrompt += "\n\nNiveau EXPERT : G√©n√®re une question difficile avec des d√©tails techniques pr√©cis."
        break
      case "marathon":
        const questionNumber = Number.parseInt(request.headers.get("x-question-number") || "1")
        if (questionNumber > 10) {
          systemPrompt += "\n\nNiveau AVANC√â : G√©n√®re une question de difficult√© moyenne √† difficile."
        }
        break
      case "chrono":
        systemPrompt += "\n\nMode CHRONO : G√©n√®re une question claire et directe, facile √† comprendre rapidement."
        break
    }

    console.log("Prompt syst√®me:", systemPrompt)
    console.log("Prompt utilisateur:", userPrompt)

    // G√©n√©rer la question avec l'IA
    const result = await generateObject({
      model: openai("gpt-4o"),
      system: systemPrompt,
      prompt: userPrompt,
      schema: QuestionSchema,
      temperature: 0.8,
    })

    console.log("Question g√©n√©r√©e:", result.object)

    // Valider et retourner la question
    const question = QuestionSchema.parse(result.object)
    return NextResponse.json(question)
  } catch (error) {
    console.error("Erreur lors de la g√©n√©ration de la question:", error)

    // Retourner une question de fallback
    const fallbackQuestion = FALLBACK_QUESTIONS[Math.floor(Math.random() * FALLBACK_QUESTIONS.length)]
    console.log("Utilisation d'une question de fallback:", fallbackQuestion)

    return NextResponse.json(fallbackQuestion)
  }
}
